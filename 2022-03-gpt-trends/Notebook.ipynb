{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba122abb-fa47-4b8b-99bc-6f8f12f1296b",
   "metadata": {},
   "source": [
    "# Describing Trends with GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6ff1e-3e09-4e4b-83c2-fe8956cb61b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The Scenario\n",
    "\n",
    "Let's imagine we need to graph pageviews over seven days.\n",
    "\n",
    "For our sighted users, a simple line plot (days on the x-axis, pageviews on the y-axis) is a quick way to get a sense of what's been going on. Sighted users see an overall trend quickly, then can dig into the numbers some other way (table?) if they want to know more. The numbers are dynamic, coming directly from a database. There are lots of tools to programatically generate charts from data.\n",
    "\n",
    "But how do we cater for blind users? We need an `alt` attribute for the chart image. One option is to just list the values, but what if they are huge numbers? Imagine a screen reader saying \"Monday three hundred and twenty one thousand eight hundred and seventy nine, Tuesday ninety seven thousand two hundred and twelve...\" - it's hard to appreciate the trend, and it's an overwhelming amount of information and not useful in the way that an overall trend would be.\n",
    "\n",
    "Even showing just one week, we have relatively few numbers, but it's still going to take a lot of logic to create a big nested `if...else` block to describe every possible trend manually. And how will we handle relative changes?\n",
    "\n",
    "After all of the hype in the last few years, let's experiment with the GPT-3 model from OpenAI, and see how it _might_ solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1f3ce-57c8-4c1f-8b2f-ae3680827f60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting set up\n",
    "\n",
    "I've started by running `pip install openai` to grab the Python bindings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944fe328-5ba1-49b8-b36e-de8eb23124fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # We only need this to get our API key from the environment variable.\n",
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252eeee-b23a-4092-8167-6391101441aa",
   "metadata": {},
   "source": [
    "And a quick test that `openai.Completion.create` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b36a492-175d-4688-9b72-9d5eae03587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nThis is a test\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1648109397,\n",
      "  \"id\": \"cmpl-4pCpZBRGMXui3G1jJKJRo62DsOK2y\",\n",
      "  \"model\": \"text-davinci:002\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", prompt=\"Say this is a test\", temperature=0, max_tokens=6)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5c6f1-e4db-4218-bb32-4432095138e0",
   "metadata": {},
   "source": [
    "Looking good. \n",
    "\n",
    "There's only one `choice`, and we can see the `text` for that choice, it says `\\n\\nThis is a text\"`.\n",
    "\n",
    "In future blocks, let's just print the part we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574540d8-5835-4635-8eab-53f27ff83cfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Prompt\n",
    "\n",
    "GPT-3 works with \"completions\" - we write a \"prompt\", and it continues with what it things is most likely to come next. \n",
    "\n",
    "You can find [some examples of completions](https://beta.openai.com/examples) on OpenAI's website. \n",
    "\n",
    "For this example, let's try something like \"summarize the trend of the list of numbers [numbers] in one sentence\". I'll also set `max_tokens` to 36 (maybe about 25 words) plenty for a reasonable length sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa52aa40-ef96-4576-b9bb-65a14884d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The list of numbers is increasing.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                                    prompt=\"Summarize the trend of the list of numbers 132, 329, 583, 743, 966, 1123, 1298 in one sentence\", \n",
    "                                    temperature=0, \n",
    "                                    max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e7910-3473-42c7-b281-160166d92584",
   "metadata": {},
   "source": [
    "Not a bad start, they definitely are increasing, but we're still missing a lot of potentially useful information - what are they increasing from and to? What is the list of numbers?\n",
    "\n",
    "GPT-3 certainly recognises the concepts here, which is impressive, but it could be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098562ef-a812-4d06-9b97-825062eaf75a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Show some examples\n",
    "\n",
    "Let's try showing some examples of what we'd like to see. Let's use these numbers as one example, then let's try another example with a different type of trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ab99d1-fde9-4152-a41f-c9aeaf8b34cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The numbers decrease steadily from just under 100 to just under 83.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                                    prompt=\"\"\"Summarize the trend of the list of numbers in one sentence\n",
    "\n",
    "Numbers: 132, 329, 583, 743, 966, 1123, 1298\n",
    "Trend: The numbers increase steadily from just over 100 to almost 1300.\n",
    "\n",
    "Numbers: 300, 323, 293, 313, 341, 301, 329\n",
    "Trend: The numbers fluctuate between 293 and 341.\n",
    "\n",
    "Numbers: 99, 97, 96, 90, 87, 83, 82\n",
    "Trend: \n",
    "\"\"\", \n",
    "                                    temperature=0, \n",
    "                                    max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4f6c8-45c6-4b03-9058-a7727ef06d6c",
   "metadata": {},
   "source": [
    "Slightly odd choice of wording here, but this is cool!\n",
    "\n",
    "Let's see how it handles a trend not covered by the examples at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebab106-2106-4f4e-af1c-0a07f115e62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The numbers fluctuate between 54 and 57, with one outlier at 5643.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                                    prompt=\"\"\"Summarize the trend of the list of numbers in one sentence\n",
    "\n",
    "Numbers: 132, 329, 583, 743, 966, 1123, 1298\n",
    "Trend: The numbers increase steadily from just over 100 to almost 1300.\n",
    "\n",
    "Numbers: 300, 323, 293, 313, 341, 301, 329\n",
    "Trend: The numbers fluctuate between 293 and 341.\n",
    "\n",
    "Numbers: 55, 54, 57, 5643, 56, 55, 54\n",
    "Trend: \n",
    "\"\"\", \n",
    "                                    temperature=0, \n",
    "                                    max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743517a5-5070-4712-a7c0-4f42a5ed3c80",
   "metadata": {},
   "source": [
    "Wow. We've got the concept of an outlier without having to include it in an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d891ec-b22b-4771-833a-1a55e328ee66",
   "metadata": {},
   "source": [
    "Next, let's try adding the concept of time. We said we're dealing with one week, so let's add references to days of the week to see if we can get _when_ the outlier occurred included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a09ea7-e384-4760-957a-96969ffd4b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The numbers fluctuate between 54 and 57.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                                    prompt=\"\"\"Summarize the trend of the list of numbers in one sentence\n",
    "\n",
    "Numbers: 132, 329, 583, 743, 966, 1123, 1298\n",
    "Trend: The numbers increase steadily from just over 100 on Monday to almost 1300 on Sunday.\n",
    "\n",
    "Numbers: 300, 323, 293, 313, 341, 301, 329\n",
    "Trend: The numbers fluctuate between 293 and 341.\n",
    "\n",
    "Numbers: 55, 54, 57, 5643, 56, 55, 54\n",
    "Trend: \n",
    "\"\"\", \n",
    "                                    temperature=0, \n",
    "                                    max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb694a-2b31-4473-84dc-62269cc8b1c4",
   "metadata": {},
   "source": [
    "This tiny tweak in one of the examples completely hides the existance of the outlier. \n",
    "\n",
    "Now let's add an outlier example, but at a different scale..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51085c96-78b2-4209-88a3-c7380874da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The numbers fluctuate between 54 and 57 all week, with one outlier at 5643 on Wednesday.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                                    prompt=\"\"\"Summarize the trend of the list of numbers in one sentence\n",
    "\n",
    "Numbers: 132, 329, 583, 743, 966, 1123, 1298\n",
    "Trend: The numbers increase steadily from just over 100 on Monday to almost 1300 on Sunday.\n",
    "\n",
    "Numbers: 300, 323, 293, 313, 341, 301, 329\n",
    "Trend: The numbers fluctuate between 293 and 341 all week.\n",
    "\n",
    "Numbers: 7, 8, 11, 9, 218, 8, 8\n",
    "Trend: The numbers fluctuate between 7 and 11 all week, wih one outlier at 218 on Friday.\n",
    "\n",
    "Numbers: 55, 54, 57, 5643, 56, 55, 54\n",
    "Trend: \n",
    "\"\"\", \n",
    "                                    temperature=0, \n",
    "                                    max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d2a80-fae1-404d-a44c-fc251b550746",
   "metadata": {},
   "source": [
    "Now it's just wrong! It's got the right idea, but the day of the week is wrong.\n",
    "\n",
    "Let's see if being extra-clear in the examples helps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36f907f-60fa-4273-9762-b7ff8a045c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The numbers fluctuate between 54 and 57 all week, with one outlier at 5643 on Thursday.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                         prompt=\"\"\"Summarize the trend of the daily list of numbers in one sentence\n",
    "\n",
    "Numbers: M: 132, T: 329, W: 583, T: 743, F: 966, S: 1123, S: 1298\n",
    "Trend: The numbers increase steadily from just over 100 on Monday to almost 1300 on Sunday.\n",
    "\n",
    "Numbers: M: 300, T: 323, W: 293, T: 313, F: 341, S: 301, S: 329\n",
    "Trend: The numbers fluctuate between 293 and 341 all week.\n",
    "\n",
    "Numbers: M: 7, T: 8, W: 11, T: 9, F: 218, S: 8, S: 8\n",
    "Trend: The numbers fluctuate between 7 and 11 all week, wih one outlier at 218 on Friday.\n",
    "\n",
    "Numbers: M: 55, T: 54, W: 57, T: 5643, F: 56, S: 55, S: 54\n",
    "Trend: \n",
    "\"\"\", \n",
    "                         temperature=0, \n",
    "                         max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab4abb-8e04-41a0-bcd6-5585c5026425",
   "metadata": {},
   "source": [
    "That helped! Let's check if a two-day dip works too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee58149-9218-4f80-b7c2-fa362a1ada5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The numbers increase steadily from just over 37,000 on Monday to almost 45,000 on Friday, with a sharp decrease on Saturday and Sunday.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-002\", \n",
    "                         prompt=\"\"\"Summarize the trend of the daily list of numbers in one sentence\n",
    "\n",
    "Numbers: M: 132, T: 329, W: 583, T: 743, F: 966, S: 1123, S: 1298\n",
    "Trend: The numbers increase steadily from just over 100 on Monday to almost 1300 on Sunday.\n",
    "\n",
    "Numbers: M: 300, T: 323, W: 293, T: 313, F: 341, S: 301, S: 329\n",
    "Trend: The numbers fluctuate between 293 and 341 all week.\n",
    "\n",
    "Numbers: M: 7, T: 8, W: 11, T: 9, F: 218, S: 8, S: 8\n",
    "Trend: The numbers fluctuate between 7 and 11 all week, wih one outlier at 218 on Friday.\n",
    "\n",
    "Numbers: M: 37465, T: 52374, W: 39809, T: 30885, F: 44325, S: 230, S: 223\n",
    "Trend: \n",
    "\"\"\", \n",
    "                         temperature=0, \n",
    "                         max_tokens=36)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c88fab-f5b3-4481-813e-b1ae8ebc3d6d",
   "metadata": {},
   "source": [
    "This is OK - it's got the two days correctly identified and uses the word \"sharp\" correctly, but it gives some slightly misleading information. It says that the numbers \"increase steadily\", but they actually jump around a little, crossing 52K on Tuesday. \n",
    "\n",
    "The solution is definitely more examples, but we are moving into the territory where it might make more sense to use the API's [fine-tuning options](https://beta.openai.com/docs/guides/fine-tuning). If we don't, our prompt is getting bigger and bigger, and we will be billed (once we run out of free credit) for sending the prompt with every request. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d0810-fb7f-4fe6-986c-e580baaa4ef6",
   "metadata": {},
   "source": [
    "## Next Steps?\n",
    "\n",
    "1. Try a fine-tuned model, as described above\n",
    "2. Collect lots of examples - maybe these could be semi-automated with Mechanical Turk or a similar service?\n",
    "3. Explore what happens with different time intervals - can we pass dates instead of days?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
